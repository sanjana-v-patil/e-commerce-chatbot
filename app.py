# -*- coding: utf-8 -*-
"""FULL_WORKING_WITH_UI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W5HiNyu-tsydVzDvv6ACw8Hew3CAqLbb
"""

!pip uninstall -y requests google-ai-generativelanguage opentelemetry-api opentelemetry-sdk opentelemetry-exporter-otlp-proto-common opentelemetry-proto

import os
os.environ["PYTHONWARNINGS"] = "ignore"

print("üì¶ Installing required libraries...")

!pip install -q langchain langchain-google-genai langchain-community 2>/dev/null
!pip install -q chromadb sentence-transformers 2>/dev/null
!pip install -q pandas numpy matplotlib seaborn plotly 2>/dev/null
!pip install -q opendatasets kaggle 2>/dev/null
!pip install -q gradio 2>/dev/null

print("‚úÖ All libraries installed successfully !")

import os
os.environ["PYTHONWARNINGS"] = "ignore"

print("üì¶ Installing required libraries ...")

# Redirect all pip output (stdout + stderr) to null, keeping output clean
!pip install -q langchain langchain-google-genai langchain-community > /dev/null 2>&1
!pip install -q chromadb sentence-transformers > /dev/null 2>&1
!pip install -q pandas numpy matplotlib seaborn plotly > /dev/null 2>&1
!pip install -q opendatasets kaggle > /dev/null 2>&1
!pip install -q requests==2.32.4 google-ai-generativelanguage==0.6.15 \
opentelemetry-api==1.37.0 opentelemetry-sdk==1.37.0 \
opentelemetry-exporter-otlp-proto-common==1.37.0 opentelemetry-proto==1.37.0 \
--force-reinstall -q > /dev/null 2>&1

print("‚úÖ All libraries installed successfully!!!")

print("\nüìö Importing libraries...")

import os
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')
print("\n Imported.")

# LangChain imports
from langchain.agents import AgentExecutor, create_react_agent
from langchain.tools import Tool
from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings
from langchain.prompts import PromptTemplate
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
from langchain.memory import ConversationBufferMemory

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go

import os

print("\nüîë Setting up OpenAI API key...")

try:
    OPENAI_API_KEY = userdata.get('OPENAI_API_KEY')
    print("‚úÖ OpenAI API key loaded from Colab secrets")
except:
    print("‚ö†Ô∏è OpenAI API key not found in secrets. Please enter it manually:")
    OPENAI_API_KEY = input("Enter your OpenAI API Key: ")

os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

# ============================================================================
# STEP 4: Download Dataset from Kaggle
# ============================================================================
print("\nüì• Downloading dataset from Kaggle...")

# Setup Kaggle credentials
from google.colab import files
import json

print("\nüìã Please upload your kaggle.json file")
print("(Download it from: https://www.kaggle.com/settings -> API -> Create New Token)")
uploaded = files.upload()

# Setup Kaggle directory
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download dataset
!kaggle datasets download -d olistbr/brazilian-ecommerce
!unzip -q brazilian-ecommerce.zip

print("‚úÖ Dataset downloaded and extracted!")

print("\nüßπ Loading and cleaning dataset...")

class EcommerceDataLoader:
    def __init__(self):
        self.data = {}

    def load_all_data(self):
        """Load all CSV files"""
        csv_files = {
            'customers': 'olist_customers_dataset.csv',
            'geolocation': 'olist_geolocation_dataset.csv',
            'order_items': 'olist_order_items_dataset.csv',
            'order_payments': 'olist_order_payments_dataset.csv',
            'order_reviews': 'olist_order_reviews_dataset.csv',
            'orders': 'olist_orders_dataset.csv',
            'products': 'olist_products_dataset.csv',
            'sellers': 'olist_sellers_dataset.csv',
            'category_translation': 'product_category_name_translation.csv'
        }

        for name, filename in csv_files.items():
            try:
                self.data[name] = pd.read_csv(filename)
                print(f"‚úÖ Loaded {name}: {self.data[name].shape}")
            except Exception as e:
                print(f"‚ùå Error loading {name}: {e}")

        return self.data

    def clean_data(self):
        """Clean and preprocess data"""
        # Convert date columns
        date_columns = {
            'orders': ['order_purchase_timestamp', 'order_approved_at',
                      'order_delivered_carrier_date', 'order_delivered_customer_date',
                      'order_estimated_delivery_date'],
            'order_reviews': ['review_creation_date', 'review_answer_timestamp']
        }

        for table, cols in date_columns.items():
            if table in self.data:
                for col in cols:
                    if col in self.data[table].columns:
                        self.data[table][col] = pd.to_datetime(self.data[table][col], errors='coerce')

        # Merge category translations
        if 'products' in self.data and 'category_translation' in self.data:
            self.data['products'] = self.data['products'].merge(
                self.data['category_translation'],
                on='product_category_name',
                how='left'
            )

        # Create enriched order dataset
        if 'orders' in self.data and 'order_items' in self.data:
            self.data['orders_enriched'] = self.data['orders'].merge(
                self.data['order_items'],
                on='order_id',
                how='left'
            )

            if 'products' in self.data:
                self.data['orders_enriched'] = self.data['orders_enriched'].merge(
                    self.data['products'][['product_id', 'product_category_name_english',
                                          'product_weight_g', 'product_length_cm',
                                          'product_height_cm', 'product_width_cm']],
                    on='product_id',
                    how='left'
                )

        print("‚úÖ Data cleaned and enriched!")
        return self.data

# Load and clean data
data_loader = EcommerceDataLoader()
data = data_loader.load_all_data()
data = data_loader.clean_data()

# ============================================================================
# STEP 6: Create Data Summary for RAG
# ============================================================================
print("\nüìä Creating data summaries for RAG...")

def create_data_documentation():
    """Create comprehensive documentation of the dataset"""
    docs = []

    # Dataset overview
    overview = """
    Brazilian E-commerce Dataset Overview:
    This is a comprehensive e-commerce dataset containing information about orders,
    customers, products, sellers, and reviews from a Brazilian marketplace.

    Key Tables:
    - Customers: Customer information and location
    - Orders: Order details including status and timestamps
    - Order Items: Products within each order with pricing
    - Products: Product catalog with categories and dimensions
    - Sellers: Seller information and location
    - Reviews: Customer reviews and ratings
    - Payments: Payment information for orders
    """
    docs.append(Document(page_content=overview, metadata={"type": "overview"}))

    # Table schemas
    for table_name, df in data.items():
        if isinstance(df, pd.DataFrame) and table_name != 'orders_enriched':
            schema_info = f"""
            Table: {table_name}
            Number of records: {len(df)}
            Columns: {', '.join(df.columns.tolist())}

            Sample statistics:
            {df.describe(include='all').to_string()}

            Data types:
            {df.dtypes.to_string()}
            """
            docs.append(Document(page_content=schema_info, metadata={"type": "schema", "table": table_name}))

    # Business insights
    if 'orders_enriched' in data:
        insights = f"""
        Business Insights:
        - Total orders: {data['orders']['order_id'].nunique()}
        - Total customers: {data['customers']['customer_id'].nunique()}
        - Total products: {data['products']['product_id'].nunique()}
        - Date range: {data['orders']['order_purchase_timestamp'].min()} to {data['orders']['order_purchase_timestamp'].max()}
        - Average order value: ${data['order_items']['price'].mean():.2f}
        - Top product category: {data['products']['product_category_name_english'].mode()[0] if not data['products']['product_category_name_english'].isna().all() else 'N/A'}
        """
        docs.append(Document(page_content=insights, metadata={"type": "insights"}))

    return docs

documents = create_data_documentation()
print(f"‚úÖ Created {len(documents)} documentation chunks")

import os, contextlib, io

os.environ["PYTHONWARNINGS"] = "ignore"
os.environ["TRANSFORMERS_VERBOSITY"] = "error"

print("\nüîç Installing and setting up free embeddings...")

!pip install -q langchain-huggingface 2>/dev/null

print("‚úÖ Package installed!")

with contextlib.redirect_stdout(io.StringIO()), contextlib.redirect_stderr(io.StringIO()):
    from langchain_huggingface import HuggingFaceEmbeddings
    from langchain_community.vectorstores import Chroma

    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    vectorstore = Chroma.from_documents(
        documents=documents,
        embedding=embeddings,
        collection_name="ecommerce_data"
    )

print("‚úÖ Vector store created successfully!")
print(f"üìä Stored {len(documents)} document chunks in the vector store")

# ============================================================================
# STEP 8: Create Agent Tools
# ============================================================================
print("\nüõ†Ô∏è Creating agent tools...")

class EcommerceTools:
    def __init__(self, data):
        self.data = data

    def query_sales_data(self, query: str) -> str:
        """Query sales and order data"""
        try:
            query_lower = query.lower()

            # Top selling categories
            if 'top' in query_lower and 'category' in query_lower:
                df = self.data['orders_enriched']
                category_sales = df.groupby('product_category_name_english')['price'].agg(['sum', 'count']).sort_values('sum', ascending=False).head(10)
                return f"Top 10 selling categories:\n{category_sales.to_string()}"

            # Average order value
            if 'average' in query_lower and 'order' in query_lower:
                avg_order = self.data['order_items'].groupby('order_id')['price'].sum().mean()
                return f"Average order value: ${avg_order:.2f}"

            # Orders by status
            if 'status' in query_lower or 'order status' in query_lower:
                status_counts = self.data['orders']['order_status'].value_counts()
                return f"Orders by status:\n{status_counts.to_string()}"

            # Default: general statistics
            total_orders = self.data['orders']['order_id'].nunique()
            total_revenue = self.data['order_items']['price'].sum()
            avg_rating = self.data['order_reviews']['review_score'].mean()

            return f"""
            General Sales Statistics:
            - Total Orders: {total_orders:,}
            - Total Revenue: ${total_revenue:,.2f}
            - Average Review Score: {avg_rating:.2f}/5.0
            - Total Products: {self.data['products']['product_id'].nunique():,}
            - Total Customers: {self.data['customers']['customer_id'].nunique():,}
            """
        except Exception as e:
            return f"Error querying sales data: {str(e)}"

    def analyze_customers(self, query: str) -> str:
        """Analyze customer data"""
        try:
            # Customer distribution by state
            if 'state' in query.lower() or 'location' in query.lower():
                state_dist = self.data['customers']['customer_state'].value_counts().head(10)
                return f"Top 10 states by customer count:\n{state_dist.to_string()}"

            # Customer city distribution
            if 'city' in query.lower():
                city_dist = self.data['customers']['customer_city'].value_counts().head(10)
                return f"Top 10 cities by customer count:\n{city_dist.to_string()}"

            # Default customer stats
            total_customers = self.data['customers']['customer_id'].nunique()
            unique_states = self.data['customers']['customer_state'].nunique()
            unique_cities = self.data['customers']['customer_city'].nunique()

            return f"""
            Customer Statistics:
            - Total Customers: {total_customers:,}
            - States Covered: {unique_states}
            - Cities Covered: {unique_cities}
            """
        except Exception as e:
            return f"Error analyzing customers: {str(e)}"

    def analyze_products(self, query: str) -> str:
        """Analyze product data"""
        try:
            query_lower = query.lower()

            # Category analysis
            if 'category' in query_lower:
                categories = self.data['products']['product_category_name_english'].value_counts().head(10)
                return f"Top 10 product categories:\n{categories.to_string()}"

            # Product dimensions
            if 'dimension' in query_lower or 'size' in query_lower or 'weight' in query_lower:
                avg_weight = self.data['products']['product_weight_g'].mean()
                avg_length = self.data['products']['product_length_cm'].mean()
                avg_height = self.data['products']['product_height_cm'].mean()
                avg_width = self.data['products']['product_width_cm'].mean()

                return f"""
                Average Product Dimensions:
                - Weight: {avg_weight:.2f}g
                - Length: {avg_length:.2f}cm
                - Height: {avg_height:.2f}cm
                - Width: {avg_width:.2f}cm
                """

            # Default product stats
            total_products = self.data['products']['product_id'].nunique()
            total_categories = self.data['products']['product_category_name_english'].nunique()

            return f"""
            Product Statistics:
            - Total Products: {total_products:,}
            - Product Categories: {total_categories}
            """
        except Exception as e:
            return f"Error analyzing products: {str(e)}"

    def analyze_reviews(self, query: str) -> str:
        """Analyze review data"""
        try:
            reviews_df = self.data['order_reviews']

            # Score distribution
            if 'score' in query.lower() or 'rating' in query.lower():
                score_dist = reviews_df['review_score'].value_counts().sort_index()
                avg_score = reviews_df['review_score'].mean()
                return f"""
                Review Score Distribution:
                {score_dist.to_string()}

                Average Score: {avg_score:.2f}/5.0
                """

            # Default review stats
            total_reviews = len(reviews_df)
            avg_score = reviews_df['review_score'].mean()

            return f"""
            Review Statistics:
            - Total Reviews: {total_reviews:,}
            - Average Score: {avg_score:.2f}/5.0
            - 5-Star Reviews: {(reviews_df['review_score'] == 5).sum():,}
            - 1-Star Reviews: {(reviews_df['review_score'] == 1).sum():,}
            """
        except Exception as e:
            return f"Error analyzing reviews: {str(e)}"

    def search_knowledge_base(self, query: str) -> str:
        """Search the vector store for relevant information"""
        try:
            results = vectorstore.similarity_search(query, k=3)
            context = "\n\n".join([doc.page_content for doc in results])
            return f"Relevant information from knowledge base:\n{context}"
        except Exception as e:
            return f"Error searching knowledge base: {str(e)}"

# Initialize tools
ecommerce_tools = EcommerceTools(data)

tools = [
    Tool(
        name="Sales_Analytics",
        func=ecommerce_tools.query_sales_data,
        description="Use this to query sales data, revenue, order statistics, and top-selling categories. Input should be a question about sales or orders."
    ),
    Tool(
        name="Customer_Analytics",
        func=ecommerce_tools.analyze_customers,
        description="Use this to analyze customer distribution, demographics, and location data. Input should be a question about customers."
    ),
    Tool(
        name="Product_Analytics",
        func=ecommerce_tools.analyze_products,
        description="Use this to analyze product categories, dimensions, and catalog information. Input should be a question about products."
    ),
    Tool(
        name="Review_Analytics",
        func=ecommerce_tools.analyze_reviews,
        description="Use this to analyze customer reviews, ratings, and satisfaction scores. Input should be a question about reviews."
    ),
    Tool(
        name="Knowledge_Search",
        func=ecommerce_tools.search_knowledge_base,
        description="Use this to search the knowledge base for dataset schema, documentation, and general information. Input should be a question about the dataset structure or definitions."
    )
]

print(f"‚úÖ Created {len(tools)} agent tools")

# ============================================================================
# STEP 9: Create Multi-Agent System (Gemini-based)
# ============================================================================

print("‚öôÔ∏è Setting up Gemini-powered multi-agent system...")

# ----------------------------------------------------------------------------
# 1Ô∏è‚É£ Imports
# ----------------------------------------------------------------------------
import os
from langchain.agents import AgentExecutor, create_react_agent
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferMemory
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.tools import Tool
from langchain.agents import initialize_agent

# ----------------------------------------------------------------------------
# 2Ô∏è‚É£ Configure Gemini API key
# ----------------------------------------------------------------------------
# Make sure you have your key from Google AI Studio: https://aistudio.google.com/apikey
os.environ["GOOGLE_API_KEY"] = "ur api key"  # ‚Üê Replace with your actual key (keep it private)

# ----------------------------------------------------------------------------
# 3Ô∏è‚É£ Initialize Gemini LLM
# ----------------------------------------------------------------------------
llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-pro",   # Latest Gemini model (use 2.5 when available)
    temperature=0.3,
    google_api_key=os.environ["GOOGLE_API_KEY"]
)

# ----------------------------------------------------------------------------
# 4Ô∏è‚É£ Define agent prompt
# ----------------------------------------------------------------------------
agent_prompt = PromptTemplate.from_template("""
You are an AI assistant specialized in **Brazilian e-commerce data analysis**.
You have access to sales, customer, product, and review data.

Your core capabilities include:
- üìä Analyzing sales trends and revenue
- üë• Providing customer insights and demographics
- üì¶ Examining product catalogs and categories
- ‚≠ê Evaluating customer reviews and satisfaction
- üß† Offering business recommendations

Guidelines:
- Always give clear, accurate, and actionable insights.
- Be conversational, concise, and data-driven.
- If information is missing, politely say so and suggest what can be done.
- Think step-by-step when analyzing data.

You have access to the following tools:
{tools}

Tool Names: {tool_names}

Previous conversation:
{chat_history}

User Question: {input}

Thought: {agent_scratchpad}
""")

# ----------------------------------------------------------------------------
# 5Ô∏è‚É£ Create conversational memory
# ----------------------------------------------------------------------------
memory = ConversationBufferMemory(
    memory_key="chat_history",
    return_messages=True
)

# ----------------------------------------------------------------------------
# 6Ô∏è‚É£ Define tools
# ----------------------------------------------------------------------------
# If you already created your custom tools earlier (like data query, plot, etc.),
# make sure they're stored in a list variable named `tools`.

# Example dummy tool if none exists yet:
tools = [
    Tool(
        name="Default Response",
        func=lambda query: "Tool placeholder: No analytical tools defined yet.",
        description="Responds when no other tool is available."
    )
]

# ----------------------------------------------------------------------------
# 7Ô∏è‚É£ Create agent and executor
# ----------------------------------------------------------------------------
agent = create_react_agent(
    llm=llm,
    tools=tools,
    prompt=agent_prompt
)


# Create a simpler, single-pass conversational agent
agent_executor = initialize_agent(
    tools=tools,
    llm=llm,
    agent_type="conversational-react-description",  # handles free-form reasoning better
    memory=memory,
    verbose=False,
    max_iterations=1,   # only one reasoning round
    handle_parsing_errors=True
)

print("‚úÖ Gemini-based conversational agent created (single-response mode).")

import time
from google.api_core.exceptions import ResourceExhausted

import time

print("\nüí¨ Launching Console Chat Interface with Gemini (Stable Single-Response Mode)...")
print("="*70)
print("üõç Maersk E-commerce AI Agent (Gemini 2.5 Pro - Free Tier)")
print("Ask me about:")
print("- üìä Sales trends and revenue")
print("- üë• Customer demographics and location")
print("- üì¶ Product categories and inventory")
print("- ‚≠ê Customer reviews and satisfaction")
print("- üìà Business insights and recommendations")
print("="*70)
print("üí° Type 'exit' or 'quit' anytime to stop chatting.\n")

while True:
    user_input = input("üßë You: ").strip()
    if user_input.lower() in ["exit", "quit"]:
        print("\nüëã Goodbye! Have a great day!")
        break

    print("ü§ñ Agent: Thinking...\n")

    try:
        # Directly query the Gemini model once ‚Äî skip ReAct parsing
        response = llm.invoke(user_input)
        print("üí¨", response.content)

        # Respect Gemini Free-tier limits (1 req/30 sec)
        print("\n‚è≥ loading...")
        time.sleep(30)

    except Exception as e:
        err = str(e)
        if "quota" in err.lower() or "429" in err:
            print("‚ö† Rate limit reached! Waiting 60 seconds before retrying...")
            time.sleep(60)
        else:
            print(f"‚ùå Error: {e}")

# ======================================================================
# üí¨ Maersk E-commerce AI Agent + Gradio UI (Gemini 2.5 Pro - Free Tier)
# ======================================================================

import os
import time
import traceback
import gradio as gr
from langchain_google_genai import ChatGoogleGenerativeAI

# ----------------------------------------------------------------------
# 1Ô∏è‚É£ Gemini API setup
# ----------------------------------------------------------------------
os.environ["GOOGLE_API_KEY"] = "AIzaSyCwxrppMXMS8wPsSUeKKIHskzWHbjc1Vqo"  # replace with your valid key

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-pro",
    temperature=0.3,
    google_api_key=os.environ["GOOGLE_API_KEY"]
)

# ----------------------------------------------------------------------
# 2Ô∏è‚É£ Console Chat Interface (unchanged)
# ----------------------------------------------------------------------
print("\nüí¨ Launching Console Chat Interface with Gemini (Stable Single-Response Mode)...")
print("="*70)
print("üõç Maersk E-commerce AI Agent (Gemini 2.5 Pro - Free Tier)")
print("Ask me about:")
print("- üìä Sales trends and revenue")
print("- üë• Customer demographics and location")
print("- üì¶ Product categories and inventory")
print("- ‚≠ê Customer reviews and satisfaction")
print("- üìà Business insights and recommendations")
print("="*70)
print("üí° Type 'exit' or 'quit' anytime to stop chatting.\n")

# ----------------------------------------------------------------------
# 3Ô∏è‚É£ Function to handle Gemini responses (fixed for Gradio)
# ----------------------------------------------------------------------
def gemini_chat(user_input, history=None):
    """Handles chat input for both console and Gradio."""
    if user_input.lower() in ["exit", "quit"]:
        return "üëã Goodbye! Have a great day!"

    try:
        response = llm.invoke(user_input)
        reply = str(response.content)
        return reply
    except Exception as e:
        print("------ GEMINI ERROR ------")
        traceback.print_exc()
        print("--------------------------")
        return f"‚ùå Error: {e}"

# ----------------------------------------------------------------------
# 4Ô∏è‚É£ Console chat loop (keep as is)
# ----------------------------------------------------------------------
def run_console():
    while True:
        user_input = input("üßë You: ").strip()
        if user_input.lower() in ["exit", "quit"]:
            print("\nüëã Goodbye! Have a great day!")
            break

        print("ü§ñ Agent: Thinking...\n")
        reply = gemini_chat(user_input)
        print("üí¨", reply)

        # Respect Gemini Free-tier limits
        print("\n‚è≥ loading...")
        time.sleep(30)

# Uncomment this line to use console chat directly
# run_console()

# ----------------------------------------------------------------------
# 5Ô∏è‚É£ Gradio UI (Colab Compatible)
# ----------------------------------------------------------------------
def launch_gradio_ui():
    chatbot = gr.ChatInterface(
        fn=gemini_chat,
        title="üõç Maersk E-commerce AI Agent",
        description=(
            "Ask questions about sales trends, customer insights, inventory, and reviews "
            "(Gemini 2.5 Pro Free Tier)"
        ),
        theme="soft"
    )
    chatbot.launch(share=True, inline=True, debug=True)

# Launch UI directly in Colab
launch_gradio_ui()
